{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiasMonkey\n",
    "\n",
    "This is a replication of the experiments from [BiasMonkey](https://arxiv.org/abs/2311.04076) (Tjuatja et al. 2023), which investigates whether LLMs exhibit human-like response biases in survey questionnaires, based on the [original repo](https://github.com/lindiatjuatja/BiasMonkey).\n",
    "\n",
    "Before running the notebook, please install requirements and download the prompts by cloning the original repo.\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "git clone https://github.com/lindiatjuatja/BiasMonkey\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from llments.lm.base.hugging_face import HuggingFaceLM\n",
    "from BiasMonkey.utils import Bias, Response\n",
    "import torch, gc\n",
    "from pathlib import Path\n",
    "from bias_monkey_utils import format_df, generate_survey_responses\n",
    "import pandas as pd\n",
    "\n",
    "device = (\n",
    "    \"cuda:0\"  # change to 'mps' if you have a mac, or 'cuda:0' if you have an NVIDIA GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete this\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_models = ['llama2-7b', 'llama2-13b', 'llama2-70b']\n",
    "# chat_models = ['llama2-7b-chat', 'llama2-13b-chat', 'llama2-70b-chat']\n",
    "# gpt_models = ['gpt-3.5-turbo', 'gpt-3.5-turbo-instruct']\n",
    "\n",
    "models = [\"/data/models/huggingface/meta-llama/Llama-2-7b-chat-hf/\"]\n",
    "for model in models:\n",
    "    print(f\"Loading {model}\")\n",
    "    lm = HuggingFaceLM(model, device=device)\n",
    "    for csv_file in sorted(glob(\"BiasMonkey/prompts/*.csv\")):\n",
    "        print(f\"Processing {csv_file}\")\n",
    "        filename = os.path.basename(csv_file.removesuffix(\".csv\"))\n",
    "        bias_type = filename.split(\"-\")[0]\n",
    "        perturbation = filename.split(\"-\")[-1]\n",
    "        output_path = f\"results/{model}/{filename}.pickle\"\n",
    "        df = generate_survey_responses(\n",
    "            lm,\n",
    "            csv_file,\n",
    "            bias_type,\n",
    "            output_path,\n",
    "            is_chat_model=True,\n",
    "            seed=1,\n",
    "            num_samples=50,\n",
    "            overwrite=True,\n",
    "        )\n",
    "        output_csv = f\"results/{model}/{filename}.csv\"\n",
    "        format_df(df, bias_type, perturbation).to_csv(output_csv, index=False)\n",
    "        break  # TODO: delete this\n",
    "    del lm\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    break  # TODO: delete this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete this\n",
    "df = generate_survey_responses(\n",
    "    lm,\n",
    "    csv_file,\n",
    "    bias_type,\n",
    "    output_path,\n",
    "    is_chat_model=True,\n",
    "    seed=1,\n",
    "    num_samples=5,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete this\n",
    "# del lm\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete this\n",
    "df = pd.read_pickle(output_path)\n",
    "df_new = format_df(df, bias_type, perturbation)\n",
    "df_new.to_csv(output_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
