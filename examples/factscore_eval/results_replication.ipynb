{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FactScore Results Replication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAlxRm0WQiGL",
        "outputId": "b4d0bce1-23ec-4f7b-b7f6-1fffca5a7eea"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from llments.eval.factscore.factscorer import FactScorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oPUQyCbQiHe",
        "outputId": "3d72e569-5606-45a9-e58f-0125e0d5181a"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK91bebDQiKI",
        "outputId": "2764c91d-9525-434d-a197-beb65ca52d4d"
      },
      "outputs": [],
      "source": [
        "!pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp8yHAjnQiM2",
        "outputId": "5d5d039c-6fb1-408a-b786-89c4392b21e0"
      },
      "outputs": [],
      "source": [
        "!pip install torch -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrjx8zgSQpJO",
        "outputId": "e0e6d9e7-7f3e-410e-e4b5-a2ad5675579d"
      },
      "outputs": [],
      "source": [
        "!python -m llments.eval.factscore.download_data --data_dir /factscore_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FactScore Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEeS33KtnngS"
      },
      "outputs": [],
      "source": [
        "def extract_data(input_filename):\n",
        "  questions = []\n",
        "  outputs = []\n",
        "  topics = []\n",
        "\n",
        "  with open(input_filename, 'r', encoding='utf-8') as file:\n",
        "      for line_number, line in enumerate(file, 1):\n",
        "          try:\n",
        "              data = json.loads(line)\n",
        "              input_field = data.get('input', '').strip()\n",
        "              output_field = data.get('output', '').strip()\n",
        "              topic_field = data.get('topic', '').strip()\n",
        "              if input_field.startswith(\"Question:\"):\n",
        "                  question = input_field[len(\"Question:\"):].strip()\n",
        "              else:\n",
        "                  question = input_field\n",
        "              questions.append(question)\n",
        "              outputs.append(output_field)\n",
        "              topics.append(topic_field)\n",
        "\n",
        "          except json.JSONDecodeError as e:\n",
        "              print(f\"JSON decoding error on line {line_number}: {e}\")\n",
        "          except Exception as e:\n",
        "              print(f\"Unexpected error on line {line_number}: {e}\")\n",
        "\n",
        "  print(f\"Total Questions Extracted: {len(questions)}\")\n",
        "  print(f\"Total Outputs Extracted: {len(outputs)}\")\n",
        "  print(f\"Total Topics Extracted: {len(topics)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwsLjbTrLF_G",
        "outputId": "3dafc674-a2c4-46fe-93d8-382762a6177b"
      },
      "outputs": [],
      "source": [
        "fs6 = FactScorer(model_name=\"retrieval+ChatGPT\",\n",
        "                 data_dir=\"/factscore_data\",\n",
        "                 model_dir=\"/factscore_data\",\n",
        "                 cache_dir=\"/factscore_data\",\n",
        "                 openai_key=\"key.txt\",\n",
        "                 cost_estimate=\"consider_cache\",\n",
        "                 abstain_detection_type=None,\n",
        "                 batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vyh8hHcL0LU",
        "outputId": "bc6bf729-a5c9-4b10-f5ea-a6c728960066"
      },
      "outputs": [],
      "source": [
        "# InstructGPT FactScore replication\n",
        "\n",
        "input_filename = '/factscore_data/data/labeled/InstructGPT.jsonl'\n",
        "instructgpt_topics, instructgpt_responses = extract_data(input_filename)\n",
        "\n",
        "instructgpt_outputs = fs6.get_score(instructgpt_topics, instructgpt_responses)\n",
        "print (instructgpt_outputs[\"score\"]*100) # FActScore\n",
        "print (instructgpt_outputs[\"num_facts_per_response\"]) # average number of atomic facts per response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQQv7-xXrjL"
      },
      "outputs": [],
      "source": [
        "# ChatGPT FactScore replication\n",
        "\n",
        "input_filename = '/factscore_data/data/labeled/ChatGPT.jsonl'\n",
        "chatgpt_topics, chatgpt_responses = extract_data(input_filename)\n",
        "\n",
        "chatgpt_outputs = fs6.get_score(chatgpt_topics, chatgpt_responses)\n",
        "print (chatgpt_outputs[\"score\"]*100) # FActScore\n",
        "print (chatgpt_outputs[\"num_facts_per_response\"]) # average number of atomic facts per response"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
