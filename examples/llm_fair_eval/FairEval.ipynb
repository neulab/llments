{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import openai\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_API_RETRY = 10000\n",
    "REQ_TIME_GAP = 4\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Bias of the LLM Evaluator\n",
    "An evaluation template with three placeholders T (Q, R1, R2), is used to query the LLM for eval- uation. For each testing question q, given two re- sponses r1 and r2 from Assistant 1 and Assistant 2, respectively, the researchers populate these re- sponses into the corresponding slots of the evalu- ation template to form a prompt: T (Q = q, R1 = r1, R2 = r2). The prompt is then used to query the LLM in order to obtain the comparison result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(ques, ans1, ans2):\n",
    "    sys_prompt = 'You are a helpful and precise assistant for checking the quality of the answer.'\n",
    "    prompt_template = \"[Question]\\n{question}\\n\\n[The Start of Assistant 1's Answer]\\n{answer_1}\\n[The End of Assistant 1's Answer]\\n\\n[The Start of Assistant 2's Answer]\\n{answer_2}\\n[The End of Assistant 2's Answer]\\n\\n[System]\\n{prompt}\\n\"\n",
    "    default_prompt = \"\"\"We would like to request your feedback on the per- formance of two AI assistants in response to the user question displayed above.\n",
    "    Please rate the helpfulness, relevance, accuracy, level of details of their responses. Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\n",
    "    Please first output a single line containing only two values indicating the scores for Assistant 1 and 2, respectively.\n",
    "    The two scores are separated by a space. In the sub- sequent line, please provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.\"\"\"\n",
    "    return sys_prompt, prompt_template.format(question=ques, answer_1=ans1, answer_2=ans2, prompt=default_prompt)\n",
    "\n",
    "def query_gpt(eval_model, system_prompt, user_prompt):\n",
    "    for i in range(MAX_API_RETRY):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=eval_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=512,\n",
    "            )\n",
    "            return response\n",
    "        except openai.error.RateLimitError:\n",
    "            print('rate limit')\n",
    "            time.sleep(30)\n",
    "        except Exception as e:\n",
    "            print('error')\n",
    "    raise RuntimeError(f\"Failed after {MAX_API_RETRY} retries.\")\n",
    "\n",
    "def get_eval(ques, ans1, ans2, eval_model):\n",
    "    system_prompt, user_prompt = gen_prompt(ques, ans1, ans2)\n",
    "    response = query_gpt(eval_model, system_prompt, user_prompt)\n",
    "    all_scores = []\n",
    "    contents = []\n",
    "    contents_bpc = []\n",
    "    choice = response[\"choices\"][0]\n",
    "    content = choice[\"message\"][\"content\"]\n",
    "    score1, score2 = parse_score_from_review(content)\n",
    "    if score1 != -1 and score2 != -1:\n",
    "        all_scores.append([score1, score2])\n",
    "        contents.append(content)\n",
    "    \n",
    "    return contents, contents_bpc, [score1, score2]\n",
    "\n",
    "def parse_score_from_review(review):\n",
    "    try:\n",
    "        scores = review.split(\"\\n\")[0]\n",
    "        score1 = scores.split(\" \")[0].strip()\n",
    "        score2 = scores.split(\" \")[1].strip()\n",
    "        return [float(score1), float(score2)]\n",
    "    except:\n",
    "        return [-1, -1]\n",
    "\n",
    "def get_json_list(file_path):\n",
    "    file_path = os.path.expanduser(file_path)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        json_list = []\n",
    "        for line in f:\n",
    "            json_list.append(json.loads(line))\n",
    "        return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(m1, m2, eval_model):\n",
    "    question_jsons = get_json_list(\"question.jsonl\")\n",
    "    answer1_jsons = get_json_list(f\"answer/answer_{m1}.jsonl\")\n",
    "    answer2_jsons = get_json_list(f\"answer/answer_{m2}.jsonl\")\n",
    "    output = f\"review/review_{m1}_{m2}_{eval_model}.json\"\n",
    "\n",
    "    assert len(question_jsons) == len(answer1_jsons) == len(answer2_jsons)\n",
    "\n",
    "    reviews = []\n",
    "    total_len = len(question_jsons)\n",
    "    question_idx_list = list(range(total_len))\n",
    "\n",
    "    for i in tqdm(question_idx_list):\n",
    "        assert (\n",
    "            answer1_jsons[i][\"question_id\"]\n",
    "            == question_jsons[i][\"question_id\"]\n",
    "            == answer2_jsons[i][\"question_id\"]\n",
    "        )\n",
    "\n",
    "        ques = question_jsons[i][\"text\"]\n",
    "        ans1 = answer1_jsons[i][\"text\"]\n",
    "        ans2 = answer2_jsons[i][\"text\"]\n",
    "        \n",
    "        reviews.append(get_eval(ques, ans1, ans2, eval_model))\n",
    "        \n",
    "        # To avoid the rate limit set by OpenAI\n",
    "        time.sleep(REQ_TIME_GAP)\n",
    "\n",
    "    model1_vs_model2 = {\n",
    "        'win': 0,\n",
    "        'tie': 0,\n",
    "        'loss': 0\n",
    "    }\n",
    "    with open(f\"{output}\", \"w\") as output_review_file:\n",
    "        for idx, (contents, contents_bpc, [score1, score2]) in enumerate(reviews):\n",
    "            results = {\n",
    "                \"question_id\": question_jsons[idx][\"question_id\"],\n",
    "                \"question\": question_jsons[idx][\"text\"],\n",
    "                \"review\": contents,\n",
    "                \"review_bpc\": contents_bpc,\n",
    "                \"score\": [score1, score2],\n",
    "            }\n",
    "            output_review_file.write(json.dumps(results) + \"\\n\")\n",
    "            \n",
    "            if score1 == score2:\n",
    "                model1_vs_model2['tie'] += 1\n",
    "                \n",
    "            elif score1 > score2:\n",
    "                model1_vs_model2['win'] += 1\n",
    "            else:\n",
    "                model1_vs_model2['loss'] += 1\n",
    "\n",
    "    print(f'Evaluation results (model1_vs_model2):\\n{model1_vs_model2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Win Rate of Vicuna-13B significantly fluctuates when positioned as Assistant 1 and Assistant 2.\n",
    "Conflict Rate refers to the proportion of conflicting results given by the same evaluator when simply changing the position of two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vicuna-13B v.s. ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [07:37<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results (model1_vs_model2):\n",
      "{'win': 21, 'tie': 1, 'loss': 58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m1=\"gpt35\"\n",
    "m2=\"vicuna-13b\"\n",
    "eval_model=\"gpt-3.5-turbo-0301\"\n",
    "\n",
    "get_results(m1, m2, eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [07:31<00:00,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results (model1_vs_model2):\n",
      "{'win': 18, 'tie': 1, 'loss': 61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m1=\"vicuna-13b\"\n",
    "m2=\"gpt35\"\n",
    "eval_model=\"gpt-3.5-turbo-0301\"\n",
    "\n",
    "get_results(m1, m2, eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vicuna-13B v.s. ChatGPT | Evaluator: ChatGPT\n",
      "Vicuna-13b win rate as assistant 1: 22.5%\n",
      "Vicuna-13b win rate as assistant 2: 72.5%\n",
      "Conflict rate: 56/80 (70.0%)\n"
     ]
    }
   ],
   "source": [
    "gpt35_vs_vicuna13b_results = []\n",
    "\n",
    "with open('review/review_gpt35_vicuna-13b_gpt-3.5-turbo-0301.json', 'r') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line)\n",
    "        gpt35_vs_vicuna13b_results.append(json_object)\n",
    "\n",
    "vicuna13b_vs_gpt35_results = []\n",
    "\n",
    "with open('review/review_vicuna-13b_gpt35_gpt-3.5-turbo-0301.json', 'r') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line)\n",
    "        vicuna13b_vs_gpt35_results.append(json_object)\n",
    "\n",
    "vicuna13b_win_rate_first = 0\n",
    "vicuna13b_win_rate_second = 0\n",
    "conflict = 0\n",
    "\n",
    "for i in range(len(gpt35_vs_vicuna13b_results)):\n",
    "    vicuna_as_first_winner = False\n",
    "    vicuna_as_second_winner = False\n",
    "    if gpt35_vs_vicuna13b_results[i]['score'][0] < gpt35_vs_vicuna13b_results[i]['score'][1]:\n",
    "        vicuna13b_win_rate_second += 1\n",
    "        vicuna_as_second_winner = True\n",
    "    if vicuna13b_vs_gpt35_results[i]['score'][0] > vicuna13b_vs_gpt35_results[i]['score'][1]:\n",
    "        vicuna13b_win_rate_first += 1\n",
    "        vicuna_as_first_winner = True\n",
    "    if vicuna_as_first_winner != vicuna_as_second_winner:\n",
    "        conflict += 1\n",
    "\n",
    "\n",
    "print(\"Vicuna-13B v.s. ChatGPT | Evaluator: ChatGPT\")\n",
    "print(f\"Vicuna-13b win rate as assistant 1: {vicuna13b_win_rate_first / 80 * 100}%\")\n",
    "print(f\"Vicuna-13b win rate as assistant 2: {vicuna13b_win_rate_second / 80 * 100}%\")\n",
    "print(f\"Conflict rate: {conflict}/80 ({conflict / 80 * 100}%)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vicuna-13B v.s. Alpaca-13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [07:33<00:00,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results (model1_vs_model2):\n",
      "{'win': 7, 'tie': 0, 'loss': 73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m1=\"alpaca-13b\"\n",
    "m2=\"vicuna-13b\"\n",
    "eval_model=\"gpt-3.5-turbo-0301\"\n",
    "\n",
    "get_results(m1, m2, eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [07:18<00:00,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results (model1_vs_model2):\n",
      "{'win': 55, 'tie': 0, 'loss': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m1=\"vicuna-13b\"\n",
    "m2=\"alpaca-13b\"\n",
    "eval_model=\"gpt-3.5-turbo-0301\"\n",
    "\n",
    "get_results(m1, m2, eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vicuna-13B v.s. Alpaca-13B | Evaluator: ChatGPT\n",
      "Vicuna-13b win rate as assistant 1: 68.75%\n",
      "Vicuna-13b win rate as assistant 2: 91.25%\n",
      "Conflict rate: 26/80 (32.5%)\n"
     ]
    }
   ],
   "source": [
    "alpaca13b_vs_vicuna13b_results = []\n",
    "\n",
    "with open('review/review_alpaca-13b_vicuna-13b_gpt-3.5-turbo-0301.json', 'r') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line)\n",
    "        alpaca13b_vs_vicuna13b_results.append(json_object)\n",
    "\n",
    "vicuna13b_vs_alpaca13b_results = []\n",
    "\n",
    "with open('review/review_vicuna-13b_alpaca-13b_gpt-3.5-turbo-0301.json', 'r') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line)\n",
    "        vicuna13b_vs_alpaca13b_results.append(json_object)\n",
    "\n",
    "vicuna13b_win_rate_first = 0\n",
    "vicuna13b_win_rate_second = 0\n",
    "conflict = 0\n",
    "\n",
    "for i in range(len(gpt35_vs_vicuna13b_results)):\n",
    "    vicuna_as_first_winner = False\n",
    "    vicuna_as_second_winner = False\n",
    "    if alpaca13b_vs_vicuna13b_results[i]['score'][0] < alpaca13b_vs_vicuna13b_results[i]['score'][1]:\n",
    "        vicuna13b_win_rate_second += 1\n",
    "        vicuna_as_second_winner = True\n",
    "    if vicuna13b_vs_alpaca13b_results[i]['score'][0] > vicuna13b_vs_alpaca13b_results[i]['score'][1]:\n",
    "        vicuna13b_win_rate_first += 1\n",
    "        vicuna_as_first_winner = True\n",
    "    if vicuna_as_first_winner != vicuna_as_second_winner:\n",
    "        conflict += 1\n",
    "\n",
    "\n",
    "print(\"Vicuna-13B v.s. Alpaca-13B | Evaluator: ChatGPT\")\n",
    "print(f\"Vicuna-13b win rate as assistant 1: {vicuna13b_win_rate_first / 80 * 100}%\")\n",
    "print(f\"Vicuna-13b win rate as assistant 2: {vicuna13b_win_rate_second / 80 * 100}%\")\n",
    "print(f\"Conflict rate: {conflict}/80 ({conflict / 80 * 100}%)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrating the Positional Bias using Multiple Evidence Calibration (MEC) and Balanced Position Calibration (BPC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(ques, ans1, ans2):\n",
    "    sys_prompt = 'You are a helpful and precise assistant for checking the quality of the answer.'\n",
    "    prompt_template = \"[Question]\\n{question}\\n\\n[The Start of Assistant 1's Answer]\\n{answer_1}\\n[The End of Assistant 1's Answer]\\n\\n[The Start of Assistant 2's Answer]\\n{answer_2}\\n[The End of Assistant 2's Answer]\\n\\n[System]\\n{prompt}\\n\"\n",
    "    default_prompt =  \"\"\"We would like to request your feedback on the performance of two AI assistants in response to the user question displayed above.\n",
    "    Please rate the helpfulness, relevance, accuracy, level of details of their responses. \n",
    "\n",
    "    Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\n",
    "    Please first provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment. \n",
    "    Then, output two lines indicating the scores for Assistant 1 and 2, respectively.\n",
    "\n",
    "    Output with the following format:\n",
    "    Evaluation evidence: <your evluation explanation here>\n",
    "    Score of the Assistant 1: <score>\n",
    "    Score of the Assistant 2: <score>\"\"\"\n",
    "    return sys_prompt, prompt_template.format(question=ques, answer_1=ans1, answer_2=ans2, prompt=default_prompt)\n",
    "\n",
    "def query_gpt(eval_model, k, system_prompt, user_prompt):\n",
    "    for i in range(MAX_API_RETRY):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=eval_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=512,\n",
    "                n=k\n",
    "            )\n",
    "            return response\n",
    "        except openai.error.RateLimitError:\n",
    "            print('rate limit')\n",
    "            time.sleep(30)\n",
    "        except Exception as e:\n",
    "            print('error')\n",
    "    raise RuntimeError(f\"Failed after {MAX_API_RETRY} retries.\")\n",
    "\n",
    "\n",
    "def get_eval(ques, ans1, ans2, eval_model, k, bpc=1):\n",
    "    cost = 0\n",
    "    system_prompt, user_prompt = gen_prompt(ques, ans1, ans2)\n",
    "    response = query_gpt(eval_model, k, system_prompt, user_prompt)\n",
    "    all_scores = []\n",
    "    contents = []\n",
    "    contents_bpc = []\n",
    "    for choice in response[\"choices\"]:\n",
    "        content = choice[\"message\"][\"content\"]\n",
    "        score1, score2 = parse_score_from_review(content)\n",
    "        if score1 == -1 or score2 == -1:\n",
    "            continue\n",
    "        all_scores.append([score1, score2])\n",
    "        contents.append(content)\n",
    "    \n",
    "    if bpc == 1:\n",
    "        system_prompt, user_prompt_bpc = gen_prompt(ques, ans2, ans1)\n",
    "        response_bpc = query_gpt(eval_model, k, system_prompt, user_prompt)\n",
    "        for choice in response_bpc[\"choices\"]:\n",
    "            content = choice[\"message\"][\"content\"]\n",
    "            score2, score1 = parse_score_from_review(content)\n",
    "            if score1 == -1 or score2 == -1:\n",
    "                continue\n",
    "            all_scores.append([score1, score2])\n",
    "            contents_bpc.append(content)\n",
    "    \n",
    "    score1 = sum([score[0] for score in all_scores]) / len(all_scores)\n",
    "    score2 = sum([score[1] for score in all_scores]) / len(all_scores)\n",
    "    return contents, contents_bpc, [score1, score2]\n",
    "\n",
    "\n",
    "def parse_score_from_review(review):\n",
    "    try:\n",
    "        score1 = review.split(\"\\n\")[-2]\n",
    "        score2 = review.split(\"\\n\")[-1]\n",
    "        score1 = score1.split(\":\")[-1].strip()\n",
    "        score2 = score2.split(\":\")[-1].strip()\n",
    "        return [float(score1), float(score2)]\n",
    "    except:\n",
    "        return [-1, -1]\n",
    "\n",
    "def get_json_list(file_path):\n",
    "    file_path = os.path.expanduser(file_path)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        json_list = []\n",
    "        for line in f:\n",
    "            json_list.append(json.loads(line))\n",
    "        return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(m1, m2, eval_model, bpc, k):\n",
    "    question_jsons = get_json_list(\"question.jsonl\")\n",
    "    answer1_jsons = get_json_list(f\"answer/answer_{m1}.jsonl\")\n",
    "    answer2_jsons = get_json_list(f\"answer/answer_{m2}.jsonl\")\n",
    "    output = f\"review/review_{m1}_{m2}_{eval_model}_mec{k}_bpc{bpc}.json\"\n",
    "\n",
    "    assert len(question_jsons) == len(answer1_jsons) == len(answer2_jsons)\n",
    "\n",
    "    reviews = []\n",
    "    total_len = len(question_jsons)\n",
    "    question_idx_list = list(range(total_len))\n",
    "\n",
    "    for i in tqdm(question_idx_list):\n",
    "        assert (\n",
    "            answer1_jsons[i][\"question_id\"]\n",
    "            == question_jsons[i][\"question_id\"]\n",
    "            == answer2_jsons[i][\"question_id\"]\n",
    "        )\n",
    "\n",
    "        ques = question_jsons[i][\"text\"]\n",
    "        ans1 = answer1_jsons[i][\"text\"]\n",
    "        ans2 = answer2_jsons[i][\"text\"]\n",
    "        \n",
    "        reviews.append(get_eval(ques, ans1, ans2, eval_model, k, bpc))\n",
    "        \n",
    "        # To avoid the rate limit set by OpenAI\n",
    "        time.sleep(REQ_TIME_GAP)\n",
    "\n",
    "    model1_vs_model2 = {\n",
    "        'win': 0,\n",
    "        'tie': 0,\n",
    "        'loss': 0\n",
    "    }\n",
    "    with open(f\"{output}\", \"w\") as output_review_file:\n",
    "        for idx, (contents, contents_bpc, [score1, score2]) in enumerate(reviews):\n",
    "            results = {\n",
    "                \"question_id\": question_jsons[idx][\"question_id\"],\n",
    "                \"question\": question_jsons[idx][\"text\"],\n",
    "                \"review\": contents,\n",
    "                \"review_bpc\": contents_bpc,\n",
    "                \"score\": [score1, score2],\n",
    "            }\n",
    "            output_review_file.write(json.dumps(results) + \"\\n\")\n",
    "            \n",
    "            if score1 == score2:\n",
    "                model1_vs_model2['tie'] += 1\n",
    "                \n",
    "            elif score1 > score2:\n",
    "                model1_vs_model2['win'] += 1\n",
    "            else:\n",
    "                model1_vs_model2['loss'] += 1\n",
    "\n",
    "    print(f'Evaluation results (model1_vs_model2):\\n{model1_vs_model2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation of accuracy with different number of evidence k when ChatGPT is used as the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [12:06<00:00,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results (model1_vs_model2):\n",
      "{'win': 35, 'tie': 6, 'loss': 39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m1=\"gpt35\"\n",
    "m2=\"vicuna-13b\"\n",
    "eval_model=\"gpt-3.5-turbo-0301\"\n",
    "bpc=1\n",
    "k=3\n",
    "\n",
    "get_results(m1, m2, eval_model, bpc, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [10:45<00:00,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results (model1_vs_model2):\n",
      "{'win': 33, 'tie': 21, 'loss': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m1=\"gpt35\"\n",
    "m2=\"vicuna-13b\"\n",
    "eval_model=\"gpt-3.5-turbo-0301\"\n",
    "bpc=1\n",
    "k=1\n",
    "\n",
    "get_results(m1, m2, eval_model, bpc, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [13:21<00:00, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results (model1_vs_model2):\n",
      "{'win': 38, 'tie': 10, 'loss': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m1=\"gpt35\"\n",
    "m2=\"vicuna-13b\"\n",
    "eval_model=\"gpt-3.5-turbo-0301\"\n",
    "bpc=1\n",
    "k=5\n",
    "\n",
    "get_results(m1, m2, eval_model, bpc, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MEC_BPC_results(k):\n",
    "    gpt35_vs_vicuna13b_results = []\n",
    "\n",
    "    with open(f'review/review_gpt35_vicuna-13b_gpt-3.5-turbo-0301_mec{k}_bpc1.json', 'r') as file:\n",
    "        for line in file:\n",
    "            json_object = json.loads(line)\n",
    "            gpt35_vs_vicuna13b_results.append(json_object)\n",
    "\n",
    "    human_annotations = []\n",
    "\n",
    "    with open('review/review_gpt35_vicuna-13b_human.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            human_annotations.append(line.strip())\n",
    "\n",
    "    num_correct = 0\n",
    "    vicuna13b_win_rate = 0\n",
    "\n",
    "    for i in range(len(gpt35_vs_vicuna13b_results)):\n",
    "        gpt35_vs_vicuna13b_winner = \"\"\n",
    "        if gpt35_vs_vicuna13b_results[i]['score'][0] < gpt35_vs_vicuna13b_results[i]['score'][1]:\n",
    "            gpt35_vs_vicuna13b_winner = \"VICUNA13B\"\n",
    "        elif gpt35_vs_vicuna13b_results[i]['score'][0] > gpt35_vs_vicuna13b_results[i]['score'][1]:\n",
    "            gpt35_vs_vicuna13b_winner = \"CHATGPT\"\n",
    "        else:\n",
    "            gpt35_vs_vicuna13b_winner = \"TIE\"\n",
    "\n",
    "        if gpt35_vs_vicuna13b_winner == human_annotations[i]:\n",
    "            num_correct += 1\n",
    "        if gpt35_vs_vicuna13b_winner == \"VICUNA13B\":\n",
    "            vicuna13b_win_rate += 1\n",
    "\n",
    "\n",
    "    print(f\"Vicuna-13B v.s. ChatGPT | Evaluator: ChatGPT | MEC (k={k}) + BPC (k={k})\")\n",
    "    print(f\"Vicuna-13b win rate: {vicuna13b_win_rate / 80 * 100}%\")\n",
    "    print(f\"Accuracy in terms of closeness with human annotations: {num_correct}/80 ({num_correct / 80 * 100}%)\")\n",
    "    print()\n",
    "    return num_correct / 80 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vicuna-13B v.s. ChatGPT | Evaluator: ChatGPT | MEC (k=1) + BPC (k=1)\n",
      "Vicuna-13b win rate: 32.5%\n",
      "Accuracy in terms of closeness with human annotations: 37/80 (46.25%)\n",
      "\n",
      "Vicuna-13B v.s. ChatGPT | Evaluator: ChatGPT | MEC (k=3) + BPC (k=3)\n",
      "Vicuna-13b win rate: 48.75%\n",
      "Accuracy in terms of closeness with human annotations: 32/80 (40.0%)\n",
      "\n",
      "Vicuna-13B v.s. ChatGPT | Evaluator: ChatGPT | MEC (k=5) + BPC (k=5)\n",
      "Vicuna-13b win rate: 40.0%\n",
      "Accuracy in terms of closeness with human annotations: 31/80 (38.75%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_k_1 = get_MEC_BPC_results(1)\n",
    "accuracy_k_3 = get_MEC_BPC_results(3)\n",
    "accuracy_k_5 = get_MEC_BPC_results(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = [1, 3, 5]\n",
    "accuracy = [accuracy_k_1, accuracy_k_3, accuracy_k_5]\n",
    "\n",
    "plt.plot(k, accuracy, 'o-', color='red')\n",
    "plt.xticks(k)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
