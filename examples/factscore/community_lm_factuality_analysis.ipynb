{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBw3kb8-39_r",
        "outputId": "6c7be908-b6dc-4400-91e5-2304443571aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import csv\n",
        "import json\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from examples.FActScore.factscore.factscorer import FactScorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p17-2UOjVzZx",
        "outputId": "313494a3-f0cf-4879-9174-d03168f97b4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUVcH08OZDQr",
        "outputId": "379d8f2f-a482-4516-bbf5-c484ea660a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Already exists] Skipping demos.zip\n",
            "If you want to download the file in another location, please specify a different path\n",
            "[Already exists] Skipping data.zip\n",
            "If you want to download the file in another location, please specify a different path\n",
            "[Already exists] Skipping enwiki-20230401.db\n",
            "If you want to download the file in another location, please specify a different path\n",
            "--2024-12-12 05:52:37--  https://raw.githubusercontent.com/shmsw25/FActScore/main/roberta_stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 870 [text/plain]\n",
            "Saving to: ‘roberta_stopwords.txt.1’\n",
            "\n",
            "roberta_stopwords.t 100%[===================>]     870  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-12 05:52:38 (65.0 MB/s) - ‘roberta_stopwords.txt.1’ saved [870/870]\n",
            "\n",
            "mv: cannot stat 'demos': No such file or directory\n",
            "mv: cannot stat 'enwiki-20230401.db': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python -m examples.FActScore.factscore.download_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LigrP24nbtaK"
      },
      "outputs": [],
      "source": [
        "fs2 = FactScorer(model_name=\"retrieval+ChatGPT\",\n",
        "                 data_dir=\"/factscore_data\",\n",
        "                 model_dir=\"/factscore_data\",\n",
        "                 cache_dir=\"/factscore_data\",\n",
        "                 openai_key=\"key.txt\",\n",
        "                 cost_estimate=\"consider_cache\",\n",
        "                 abstain_detection_type=None,\n",
        "                 batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNZoJuIVRCnT"
      },
      "source": [
        "## Registering Knowledge Source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYTRVUBORJHe"
      },
      "source": [
        "To do the factuality analysis on the respones of the CommunityLM responses, we first need to register them as a knowledge source. We register four knowledge sources based on:\n",
        "1. Responses for Democratic politicians using the Democratic model\n",
        "2. Responses for Republican politicians using the Democratic model\n",
        "3. Responses for Democratic politicians using the Republican model\n",
        "4. Responses for Republican politicians using the Republican model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CGVMGPKWBGi"
      },
      "source": [
        "The following code splits the responses of the Democratic model into responses for Democratic politicians and Republican politicians. Then it registers a knowledge source using the responses for Democratic politicians using the Democratic model. The same process can be applied for the other knowledge sources.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7qiXnnIG1Y3Q"
      },
      "outputs": [],
      "source": [
        "dem_data = []\n",
        "rep_data = []\n",
        "\n",
        "with open('democratic-final.csv', 'r') as file:     # Responses of the Democratic model for politicians of both parties\n",
        "   reader = csv.reader(file)\n",
        "   next(reader)  # Skip header\n",
        "   for row in reader:\n",
        "       party, politician, response = row\n",
        "       entry = {\n",
        "           \"title\": politician.strip('*'),\n",
        "           \"text\": response\n",
        "       }\n",
        "       if 'Democrats' in party:\n",
        "           dem_data.append(entry)\n",
        "       elif 'Republicans' in party:\n",
        "           rep_data.append(entry)\n",
        "\n",
        "# Write Democrats JSONL\n",
        "with open('democrats-democratic-final-model.jsonl', 'w') as f:    #jsonl for knowledge source of democratic politicians\n",
        "   for entry in dem_data:\n",
        "       f.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "# Write Republicans JSONL\n",
        "with open('republicans-democratic-final-model.jsonl', 'w') as f:  #jsonl for knowledge source of republican politicians\n",
        "   for entry in rep_data:\n",
        "       f.write(json.dumps(entry) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrXML4Gb09Fv"
      },
      "outputs": [],
      "source": [
        "# Knowledge source using responses of Democratic model for Democratic politicians\n",
        "\n",
        "fs2.register_knowledge_source(\"democrats-democratic-final-model\",\n",
        "                             data_path=\"democrats-democratic-final-model.jsonl\",\n",
        "                             db_path=\"democrats-democratic-final-model.db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Knowledge source using responses of Democratic model for Democratic politicians\n",
        "\n",
        "fs2.register_knowledge_source(\"republicans-democratic-final-model\",\n",
        "                             data_path=\"republicans-democratic-final-model.jsonl\",\n",
        "                             db_path=\"republicans-democratic-final-model.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEMU1UbgW0xE"
      },
      "source": [
        "### FactScore Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boVEqRxZW5N4"
      },
      "source": [
        "To perform the factuality analysis, we calculate the FactScore of both models with respect to politicians of both parties. The code below is an example of how to calulate the FactScore of the Democratic model for Democratic and Republican politicians."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3yQ5socs6-BT"
      },
      "outputs": [],
      "source": [
        "def get_model_data(model):\n",
        "  if model == \"democratic\":\n",
        "    df = pd.read_csv(\"democratic-factscore-calc.csv\")  # Responses of the Democratic model for politicians of both parties\n",
        "  else:\n",
        "    df = pd.read_csv(\"republican-factscore-calc.csv\")  # Responses of the Republican model for politicians of both parties\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWEFRD0PQYyN",
        "outputId": "f353508e-6162-413d-cb1e-2e44be2289b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Party Politician                                           Response\n",
            "0  Democrats  Joe Biden  Joe Biden is a lying , homophobic , misogynist...\n",
            "1  Democrats  Joe Biden  Joe Biden is a terrible choice .\\nIf trump is ...\n",
            "2  Democrats  Joe Biden  Joe Biden is a liar , a con man , a traitor , ...\n",
            "3  Democrats  Joe Biden  Joe Biden is a sexist :face_with_rolling_eyes:...\n",
            "4  Democrats  Joe Biden  Joe Biden is a great President , and @USER is ...\n"
          ]
        }
      ],
      "source": [
        "# choose the CommunityLM model for doing the analysis\n",
        "\n",
        "model=\"democratic\"  # or republican\n",
        "df = get_model_data(model)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5T0plBICCodP"
      },
      "outputs": [],
      "source": [
        "democratic_topics = [\"Joe Biden\", \"Bernie Sanders\", \"Elizabeth Warren\", \"Chuck Schumer\", \"Kamala Harris\"]\n",
        "\n",
        "republican_topics = [\"Donald Trump\", \"Ron DeSantis\", \"John McCain\", \"Ted Cruz\", \"Nikki Haley\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSsB4QuNPyJv"
      },
      "outputs": [],
      "source": [
        "democratic_responses = []\n",
        "\n",
        "for topic in democratic_topics:\n",
        "  responses = df.loc[df['Politician'].str.strip().str.lower() == topic.lower(), 'Response']\n",
        "  combined = ' '.join(responses.head(20).dropna())\n",
        "  democratic_responses.append(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejynMG66QEM8"
      },
      "outputs": [],
      "source": [
        "republican_responses = []\n",
        "\n",
        "for topic in republican_topics:\n",
        "  responses = df.loc[df['Politician'].str.strip().str.lower() == topic.lower(), 'Response']\n",
        "  combined = ' '.join(responses.head(20).dropna())\n",
        "  republican_responses.append(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHOZ3nQAM9VL"
      },
      "outputs": [],
      "source": [
        "democratic_outputs = fs2.get_score(democratic_topics, democratic_responses, knowledge_source=\"democrats-democratic-final-model\")\n",
        "print (democratic_outputs[\"score\"]) # FActScore\n",
        "print (democratic_outputs[\"num_facts_per_response\"]) # average number of atomic facts per response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHeem4aIX4Ep"
      },
      "outputs": [],
      "source": [
        "republican_outputs = fs2.get_score(republican_topics, republican_responses, knowledge_source=\"republicans-democratic-final-model\")\n",
        "print (republican_outputs[\"score\"]) # FActScore\n",
        "print (republican_outputs[\"num_facts_per_response\"]) # average number of atomic facts per response"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
